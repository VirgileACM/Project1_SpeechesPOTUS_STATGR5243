k <- -exp(1/2*x^2/sigma^2)/(sqrt(2*pi)*sigma)
return ( k[0:n]/sum(k[0:n]) )
}
half_gaussian_kernel(10,1)
half_gaussian_kernel <- function(n,sigma){
x <- -n:n
k <- exp(-1/2*x^2/sigma^2)/(sqrt(2*pi)*sigma)
return ( k[0:n]/sum(k[0:n]) )
}
half_gaussian_kernel(10,1)
n=10
sigma=1
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
n=800
sigma=400
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
n=800
sigma=200
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
n=800
sigma=800
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
n=800
sigma=800
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)==1
sum(y)
n=800
sigma=800
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
half_gaussian_kernel <- function(n,sigma){
x <- -n:n
k <- exp(-1/2*x^2/sigma^2)/(sqrt(2*pi)*sigma)
return ( k[0:n]/sum(k[0:n]) )
}
n=800
sigma=300
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
half_gaussian_kernel <- function(n,sigma){
'''
Calculate the coefficients of a discrete 1D Gaussian(0,sigma) kernel of length 2*n
and then takes only the part on the left of y-axis, and normalize it.
We do this to obtain a 1D exponential filter to compute a gaussian weighted average centered
on the right of our data (most recent one).
'''
x <- -n:n
k <- exp(-1/2*x^2/sigma^2)/(sqrt(2*pi)*sigma)
return ( k[0:n]/sum(k[0:n]) )
}
n=800
sigma=300
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
n=500
sigma=200
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
n=100
sigma=40
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
sigma=20
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
sigma=40
n=100
sigma=40
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
n=100
sigma=20
y<-half_gaussian_kernel(n,sigma)
plot(1:n,y)
sum(y)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
print(packages.needed)
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
packages.needed
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
ff.all<-tm_map(ff.all, stripWhitespace)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
install.packages("tidytext")
library(tidytext)
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
install.packages("contrib.url")
unlink('Google Drive/MAFN/AppliedDS/Project1/TutorialSpeech/doc/wk2-Tutorial-TextMining_cache', recursive = TRUE)
library("rvest")
library("tibble")
install.packages("rvest")
library("rvest")
library("tibble")
library("qdap")
install.packages("qdap")
library("qdap")
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
ls
library("qdap")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
#print(packages.needed)
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed) #, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
unlink('Google Drive/MAFN/AppliedDS/Project1/TutorialSpeech/doc/wk2-Tutorial-TextMining_cache', recursive = TRUE)
### Inauguaral speeches
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches.
inaug=f.speechlinks(main.page)
#head(inaug)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
#### Nomination speeches
main.page=read_html("http://www.presidency.ucsb.edu/nomination.php")
# Get link URLs
nomin <- f.speechlinks(main.page)
#head(nomin)
#
#### Farewell speeches
main.page=read_html("http://www.presidency.ucsb.edu/farewell_addresses.php")
# Get link URLs
farewell <- f.speechlinks(main.page)
#head(farewell)
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)
speech.list=rbind(inaug.list, nomin.list, farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
rep("nomin", nrow(nomin.list)),
rep("farewell", nrow(farewell.list)))
speech.url=rbind(inaug, nomin, farewell)
speech.list=cbind(speech.list, speech.url)
# Loop over each row in speech.list
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
text <- read_html(speech.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
speech.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/fulltext/",
speech.list$type[i],
speech.list$File[i], "-",
speech.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
speech1=paste(readLines("../data/fulltext/SpeechDonaldTrump-NA.txt",
n=-1, skipNul=TRUE),
collapse=" ")
speech2=paste(readLines("../data/fulltext/SpeechDonaldTrump-NA2.txt",
n=-1, skipNul=TRUE),
collapse=" ")
speech3=paste(readLines("../data/fulltext/PressDonaldTrump-NA.txt",
n=-1, skipNul=TRUE),
collapse=" ")
Trump.speeches=data.frame(
President=rep("Donald J. Trump", 3),
File=rep("DonaldJTrump", 3),
Term=rep(0, 3),
Party=rep("Republican", 3),
Date=c("August 31, 2016", "September 7, 2016", "January 11, 2017"),
Words=c(word_count(speech1), word_count(speech2), word_count(speech3)),
Win=rep("yes", 3),
type=rep("speeches", 3),
links=rep(NA, 3),
urls=rep(NA, 3),
fulltext=c(speech1, speech2, speech3)
)
speech.list=rbind(speech.list, Trump.speeches)
head(speech.list)
names(speech.list)
names(Trump.speeches)
names(inaug.list)
Trump.speeches=data.frame(
X...President=rep("Donald J. Trump", 3),
File=rep("DonaldJTrump", 3),
Term=rep(0, 3),
Party=rep("Republican", 3),
Date=c("August 31, 2016", "September 7, 2016", "January 11, 2017"),
Words=c(word_count(speech1), word_count(speech2), word_count(speech3)),
Win=rep("yes", 3),
type=rep("speeches", 3),
links=rep(NA, 3),
urls=rep(NA, 3),
fulltext=c(speech1, speech2, speech3)
)
speech.list=rbind(speech.list, Trump.speeches)
par(mfrow=c(5, 1))
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
topics.hash
View(f.speechlinks)
setwd("~/Google Drive/MAFN/AppliedDS/Project1/doc")
8460/130
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(qdap)
library(qdapTools)
# for home-made functions
#source("../lib/speechFuncs.R")
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all)
tdm.tidy=tidy(tdm.all)
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
library("readr")
library("xlsx")
# Load the texts
texts = paste(folder.path,speeches,sep="")
ing_speeches = data.frame(File=prex.out, stringsAsFactors =F)
ing_speeches$Speech = apply(as.data.frame(texts,stringsAsFactors =F),1,FUN=function(x)read_file(x))
# Put name of president, term, party
xlfile = read.xlsx2(file='../data/InaugurationInfo.xlsx',sheetIndex = 1, stringsAsFactors=F)
xlfile$File = paste(xlfile$File, xlfile$Term, sep='-')
ing_file <- merge(ing_speeches, xlfile, by='File')
ing_file$Words[9] = 1433        # fill the last row since empty
# Load and process date
dates = read.table("../data/InauguationDates.txt", sep='\t', header=T, stringsAsFactors=F)
# account for differences between db
dates[22,1] ="Grover Cleveland - I"
dates[24,1] ="Grover Cleveland - II"
dates[11,1] = "James K. Polk"
dates[20,1] = "James Garfield"
dates[8,1] = "Martin van Buren"
dates[37,1] = "Richard Nixon"
dates_processed = data.frame(President=dates$PRESIDENT[dates$FIRST!=""],Term=1, Date=dates$FIRST[dates$FIRST!=""], stringsAsFactors=F)
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$SECOND!=""],Term=2, Date=dates$SECOND[dates$SECOND!=""], stringsAsFactors=F))
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$THIRD!=""],Term=3, Date=dates$THIRD[dates$THIRD!=""], stringsAsFactors=F))
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$FOURTH!=""],Term=4, Date=dates$FOURTH[dates$FOURTH!=""], stringsAsFactors=F))
ing_file <- merge(ing_file, dates_processed, by=c('President','Term'), all.x = TRUE)
ing_file$Year <- apply(as.data.frame(ing_file$Date,stringsAsFactors =F),1,FUN=function(x)as.numeric(substr(x,nchar(x)-3,nchar(x))))
ing_file$Words <- as.numeric(ing_file$Words) # transform words to integer
# Approximation of Party to make it comparable to more recent US president
ing_file$Party[ing_file$Party=="NA"] <- "Democratic" # lincoln
ing_file$Party[ing_file$Party=="Fedralist"] <- "Democratic" # john adams
ing_file$Party[ing_file$Party=="Democratic-Republican Party"] <- "Republican"
ing_file$Party[ing_file$Party=="Whig"] <- "Republican"
source("../lib/complexityFunc.R")
ing_file$Speech[34] <- gsub("\u0097","",ing_file$Speech[34]) #avoid problems with exists()
ing_file$ReadIndex <- unlist(lapply(ing_file$Speech,FUN=ReadabilityIndexes))
# add abreviation for plotting
ing_file$Abrev <- unlist(lapply(ing_file$President,FUN=Abrev))
plot(ing_file$Words)
plot(log(ing_file$Words))
?sigmoid
source("../lib/complexityFunc.R")
plot(sigmoid(ing_file$Words))
plot(sigmoid(ing_file$Words-mean(ing_file$Words)))
plot(sigmoid((ing_file$Words-mean(ing_file$Words))/sd(ing_file$Words) )
)
plot(10*sigmoid((ing_file$Words-mean(ing_file$Words))/sd(ing_file$Words) )
)
ing_file$SigWords <- 10*sigmoid((ing_file$Words-mean(ing_file$Words))/sd(ing_file$Words))
View(ing_file)
?fviz_cluster
??fviz_cluster
which(speeches=="inaugAbrahamLincoln-1.txt")
which(speeches=="inaugAbrahamLincoln-2.txt")
View(ff.dtm)
?wordcloud
packages.used=c("tm", "wordcloud", "RColorBrewer",
"dplyr", "tydytext")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
library(qdap)
library(qdapTools)
# for home-made functions
#source("../lib/speechFuncs.R")
folder.path="../data/InauguralSpeeches/"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
ff.all<-Corpus(DirSource(folder.path))
ff.all<-tm_map(ff.all, stripWhitespace)
ff.all<-tm_map(ff.all, content_transformer(tolower))
ff.all<-tm_map(ff.all, removeWords, stopwords("english"))
ff.all<-tm_map(ff.all, removeWords, character(0))
ff.all<-tm_map(ff.all, removePunctuation)
tdm.all<-TermDocumentMatrix(ff.all)
tdm.tidy=tidy(tdm.all)
tdm.overall=summarise(group_by(tdm.tidy, term), sum(count))
library("readr")
library("xlsx")
# Load the texts
texts = paste(folder.path,speeches,sep="")
ing_speeches = data.frame(File=prex.out, stringsAsFactors =F)
ing_speeches$Speech = apply(as.data.frame(texts,stringsAsFactors =F),1,FUN=function(x)read_file(x))
# Put name of president, term, party
xlfile = read.xlsx2(file='../data/InaugurationInfo.xlsx',sheetIndex = 1, stringsAsFactors=F)
xlfile$File = paste(xlfile$File, xlfile$Term, sep='-')
ing_file <- merge(ing_speeches, xlfile, by='File')
ing_file$Words[9] = 1433        # fill the last row since empty
# Load and process date
dates = read.table("../data/InauguationDates.txt", sep='\t', header=T, stringsAsFactors=F)
# account for differences between db
dates[22,1] ="Grover Cleveland - I"
dates[24,1] ="Grover Cleveland - II"
dates[11,1] = "James K. Polk"
dates[20,1] = "James Garfield"
dates[8,1] = "Martin van Buren"
dates[37,1] = "Richard Nixon"
dates_processed = data.frame(President=dates$PRESIDENT[dates$FIRST!=""],Term=1, Date=dates$FIRST[dates$FIRST!=""], stringsAsFactors=F)
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$SECOND!=""],Term=2, Date=dates$SECOND[dates$SECOND!=""], stringsAsFactors=F))
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$THIRD!=""],Term=3, Date=dates$THIRD[dates$THIRD!=""], stringsAsFactors=F))
dates_processed <- rbind(dates_processed, data.frame(President=dates$PRESIDENT[dates$FOURTH!=""],Term=4, Date=dates$FOURTH[dates$FOURTH!=""], stringsAsFactors=F))
ing_file <- merge(ing_file, dates_processed, by=c('President','Term'), all.x = TRUE)
ing_file$Year <- apply(as.data.frame(ing_file$Date,stringsAsFactors =F),1,FUN=function(x)as.numeric(substr(x,nchar(x)-3,nchar(x))))
ing_file$Words <- as.numeric(ing_file$Words) # transform words to integer
# Approximation of Party to make it comparable to more recent US president
ing_file$Party[ing_file$Party=="NA"] <- "Democratic" # lincoln
ing_file$Party[ing_file$Party=="Fedralist"] <- "Democratic" # john adams
ing_file$Party[ing_file$Party=="Democratic-Republican Party"] <- "Republican"
ing_file$Party[ing_file$Party=="Whig"] <- "Republican"
dtm <- DocumentTermMatrix(ff.all,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
ff.dtm=tidy(dtm)
View(ff.dtm)
trump_speech_df = ff.dtm[ff.dtm$document=="inaugDonaldJTrump-1.txt",2:3]
wordcloud(trump_speech_df$term, trump_speech_df$count,
scale=c(5,0.5),
max.words=50,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(8,"Reds"))
trump_speech_df = ff.dtm[ff.dtm$document=="inaugDonaldJTrump-1.txt",2:3]
wordcloud(trump_speech_df$term, trump_speech_df$count,
scale=c(5,0.5),
max.words=50,
min.freq=1,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(8,"Reds"))
ing_file$Party[3]
ing_file$Party[2]
dict<-new.env()
dict[["Republican"]] <- "Reds"; dict[["Democratic"]] <- "Blues";
dict[[ing_file$Party[2]]]
?text
?par
?wordcloud
?text
plot(0)
frame()
?layout
?wordcloud
?layout
?geom_text
?annotate
?scale_shape_discrete
?stat_poly_eq
